{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## K Nearest Neighbor (KNN) Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "First, let's import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead), as well as Scikit-Learn ≥0.20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification, make_blobs\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "\n",
    "CHAPTER_ID = 'KNN'\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN classifier\n",
    "\n",
    "- Read KNN classifier in Python:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "\n",
    "- Check out the difference between model parameters and hyper parameters:\n",
    "https://towardsdatascience.com/model-parameters-and-hyperparameters-in-machine-learning-what-is-the-difference-702d30970f6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build KNN classifiers on a well-known dataset, iris dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(\"images/iris.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 1: iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the data from a local file: iris.csv is stored in a folder \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from CSV file to dataframe\n",
    "iris = pd.read_csv('./data/iris.csv')\n",
    "\n",
    "# define target_namees (class lables)\n",
    "target_names = ['setosa', 'versicolor', 'virginica']\n",
    "\n",
    "print(iris.head())\n",
    "print(iris.tail())\n",
    "\n",
    "# X contains the first four columns, y contains class labels\n",
    "X = iris.iloc[:, :4].to_numpy()\n",
    "y = iris['Class'].to_numpy()\n",
    "\n",
    "#print(X)\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "data = iris.iloc[:, :4]\n",
    "data.head()\n",
    "\n",
    "min_max = preprocessing.MinMaxScaler()\n",
    "\n",
    "col = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']\n",
    "normData = min_max.fit_transform(data)\n",
    "\n",
    "normData = pd.DataFrame(normData, columns = col)\n",
    "print(normData.head())\n",
    "\n",
    "X_normalized = normData.iloc[:, :4].to_numpy()\n",
    "\n",
    "#X_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Cross Validation (k = 3) on the orignal data\n",
    "\n",
    "- KNN classifier with varying k values, 1, 5, 10, 15, 20, 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=3, random_state=None, shuffle=True) # Define the split - into k folds \n",
    "\n",
    "k_values = [1, 5, 10, 15, 20, 25, 30]\n",
    "\n",
    "for k in k_values:\n",
    "    precision = []\n",
    "    recall = []\n",
    "    accuracy = []\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    \n",
    "    train_score = []\n",
    "    test_score = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        \n",
    "        X_train, y_train = X[train_index], y[train_index]\n",
    "        X_test, y_test = X[test_index], y[test_index]\n",
    "\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred = knn.predict(X_test)\n",
    "        \n",
    "        train_score.append(knn.score(X_train, y_train))\n",
    "        test_score.append(knn.score(X_test, y_test))\n",
    "        \n",
    "        #print(f\"k={k}\")\n",
    "        #print(\"training score: \", knn.score(X_train, y_train))\n",
    "        #print(\"testing score: \", knn.score(X_test, y_test))\n",
    "    \n",
    "        # plot a confusion matrix\n",
    "        confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "        #print(confusion_mat)\n",
    "    \n",
    "        #classification_report(y_test, y_pred, target_names=target_names, output_dict=True)\n",
    "        results = classification_report(y_test, y_pred, target_names=target_names)\n",
    "        #print(results)\n",
    "\n",
    "        metrics_dict = classification_report(y_test, y_pred, \n",
    "                        target_names=target_names, output_dict=True)\n",
    "\n",
    "        avg_precision = metrics_dict['weighted avg']['precision']\n",
    "        #print('precision (weighted):', avg_precision)\n",
    "        precision.append(avg_precision)\n",
    "    \n",
    "        avg_recall = metrics_dict['weighted avg']['recall']\n",
    "        #print('recall avg (weighted):', avg_recall)\n",
    "        recall.append(avg_recall)\n",
    "    \n",
    "        avg_accuracy = metrics_dict['accuracy']\n",
    "        #print('accuracy: ', avg_accuracy)\n",
    "        accuracy.append(avg_accuracy)\n",
    "        \n",
    "    print('\\n******* Performance with k =', k, '*******')\n",
    "    print('Precision: ', sum(precision)/len(precision))\n",
    "    print('Recall: ', sum(recall)/len(recall))\n",
    "    print('Accuracy: ', sum(accuracy)/len(accuracy))\n",
    "    print('**************************************\\n')\n",
    "    \n",
    "    plt.plot(k, np.mean(test_score), 'bo')\n",
    "    plt.plot(k, np.mean(train_score), 'rx')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Cross Validation (k = 3) on the orignal data\n",
    "\n",
    "- KNN classifier with varying training size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [x/10 for x in range(1, 9)]\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 10)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "for s in t:\n",
    "    train_score = []\n",
    "    test_score = []\n",
    "    for i in range(1,100):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1-s)\n",
    "        knn.fit(X_train, y_train)\n",
    "        train_score.append(knn.score(X_train, y_train))\n",
    "        test_score.append(knn.score(X_test, y_test))\n",
    "    \n",
    "    plt.plot(s, np.mean(train_score), 'rx')\n",
    "    plt.plot(s, np.mean(test_score), 'bo')\n",
    "\n",
    "plt.xlabel('Training set proportion (%)')\n",
    "plt.ylabel('accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Cross Validation (k = 3) on the normalized data\n",
    "\n",
    "- KNN classifier with varying k values, 1, 5, 10, 15, 20, 25, 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=3, random_state=None, shuffle=True) # Define the split - into k folds \n",
    "\n",
    "k_values = [1, 5, 10, 15, 20, 25, 30]\n",
    "\n",
    "for k in k_values:\n",
    "    precision = []\n",
    "    recall = []\n",
    "    accuracy = []\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    \n",
    "    train_score = []\n",
    "    test_score = []\n",
    "    for train_index, test_index in kf.split(X_normalized):\n",
    "        \n",
    "        X_train, y_train = X[train_index], y[train_index]\n",
    "        X_test, y_test = X[test_index], y[test_index]\n",
    "\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred = knn.predict(X_test)\n",
    "        \n",
    "        train_score.append(knn.score(X_train, y_train))\n",
    "        test_score.append(knn.score(X_test, y_test))\n",
    "        \n",
    "        #print(f\"k={k}\")\n",
    "        #print(\"training score: \", knn.score(X_train, y_train))\n",
    "        #print(\"testing score: \", knn.score(X_test, y_test))\n",
    "    \n",
    "        # plot a confusion matrix\n",
    "        confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "        #print(confusion_mat)\n",
    "    \n",
    "        #classification_report(y_test, y_pred, target_names=target_names, output_dict=True)\n",
    "        results = classification_report(y_test, y_pred, target_names=target_names)\n",
    "        #print(results)\n",
    "\n",
    "        metrics_dict = classification_report(y_test, y_pred, \n",
    "                        target_names=target_names, output_dict=True)\n",
    "\n",
    "        avg_precision = metrics_dict['weighted avg']['precision']\n",
    "        #print('precision (weighted):', avg_precision)\n",
    "        precision.append(avg_precision)\n",
    "    \n",
    "        avg_recall = metrics_dict['weighted avg']['recall']\n",
    "        #print('recall avg (weighted):', avg_recall)\n",
    "        recall.append(avg_recall)\n",
    "    \n",
    "        avg_accuracy = metrics_dict['accuracy']\n",
    "        #print('accuracy: ', avg_accuracy)\n",
    "        accuracy.append(avg_accuracy)\n",
    "        \n",
    "    print('\\n******* Performance with k =', k, '*******')\n",
    "    print('Precision: ', sum(precision)/len(precision))\n",
    "    print('Recall: ', sum(recall)/len(recall))\n",
    "    print('Accuracy: ', sum(accuracy)/len(accuracy))\n",
    "    print('**************************************\\n')\n",
    "    \n",
    "    plt.plot(k, np.mean(test_score), 'bo')\n",
    "    plt.plot(k, np.mean(train_score), 'rx')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Cross Validation (k = 3) on the orignal data¶\n",
    "\n",
    "KNN classifier with varying training size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [x/10 for x in range(1, 9)]\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "for s in t:\n",
    "    train_score = []\n",
    "    test_score = []\n",
    "    for i in range(1,100):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size = 1-s)\n",
    "        knn.fit(X_train, y_train)\n",
    "        train_score.append(knn.score(X_train, y_train))\n",
    "        test_score.append(knn.score(X_test, y_test))\n",
    "    \n",
    "    plt.plot(s, np.mean(train_score), 'rx')\n",
    "    plt.plot(s, np.mean(test_score), 'bo')\n",
    "\n",
    "plt.xlabel('Training set proportion (%)')\n",
    "plt.ylabel('accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayesian Classifier\n",
    "\n",
    "- The original data\n",
    "\n",
    "- modeling with varying training data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [x/10 for x in range(1, 9)]\n",
    "\n",
    "nbclf1 = GaussianNB()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "for s in t:\n",
    "    train_score = []\n",
    "    test_score = []\n",
    "    for i in range(1,100):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1-s)\n",
    "        nbclf1.fit(X_train, y_train)\n",
    "        train_score.append(nbclf1.score(X_train, y_train))\n",
    "        test_score.append(nbclf1.score(X_test, y_test))\n",
    "    \n",
    "    plt.plot(s, np.mean(train_score), 'rx')\n",
    "    plt.plot(s, np.mean(test_score), 'bo')\n",
    "\n",
    "plt.xlabel('Training set proportion (%)')\n",
    "plt.ylabel('accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayesian classifier\n",
    "\n",
    "- Normalized data\n",
    "\n",
    "- Modeling with varying training data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [x/10 for x in range(1, 9)]\n",
    "\n",
    "nbclf2 = GaussianNB()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "for s in t:\n",
    "    train_score = []\n",
    "    test_score = []\n",
    "    for i in range(1,100):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size = 1-s)\n",
    "        nbclf2.fit(X_train, y_train)\n",
    "        train_score.append(nbclf2.score(X_train, y_train))\n",
    "        test_score.append(nbclf2.score(X_test, y_test))\n",
    "    \n",
    "    plt.plot(s, np.mean(train_score), 'rx')\n",
    "    plt.plot(s, np.mean(test_score), 'bo')\n",
    "\n",
    "plt.xlabel('Training set proportion (%)')\n",
    "plt.ylabel('accuracy (normalized)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
