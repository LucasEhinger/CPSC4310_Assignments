{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "\n",
    "- Simple examples that show the following\n",
    "\n",
    "    - Train a decision tree classifier\n",
    "\n",
    "    - Evaluate the model\n",
    "\n",
    "    - Find important Features in Decision Trees\n",
    "    \n",
    "Note that we do not use k-cross validation \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"decision_trees\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important features from a decision tree using gini index\n",
    "\n",
    "- Decision tree classifier\n",
    "\n",
    "https://scikit-learn.org/stable/modules/tree.html#classification\n",
    "\n",
    "- Metrics\n",
    "\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importances(clf, feature_names):\n",
    "    c_features = len(feature_names)\n",
    "    plt.barh(range(c_features), clf.feature_importances_)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature name\")\n",
    "    plt.yticks(np.arange(c_features), feature_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 1: iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "Image(\"images/iris.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of important features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# A simple training (1 training)\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Important features from a decision tree using information gain measure (entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(criterion='gini')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model and show important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of DT classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))\n",
    "print('Accuracy of DT classifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, y_test)))\n",
    "\n",
    "plt.figure(figsize=(8,4), dpi=60)\n",
    "\n",
    "# call the function above\n",
    "plot_feature_importances(clf, iris.feature_names)\n",
    "plt.show()\n",
    "\n",
    "print('Feature importances: {}'.format(clf.feature_importances_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important features from a decision tree using information gain measure (entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train the model\n",
    "\n",
    "clf2 = DecisionTreeClassifier(criterion='entropy')\n",
    "clf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluate the model and show important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of DT classifier on training set: {:.2f}'\n",
    "     .format(clf2.score(X_train, y_train)))\n",
    "print('Accuracy of DT classifier on test set: {:.2f}'\n",
    "     .format(clf2.score(X_test, y_test)))\n",
    "\n",
    "plt.figure(figsize=(8,4), dpi=60)\n",
    "plot_feature_importances(clf2, iris.feature_names)\n",
    "plt.show()\n",
    "\n",
    "print('Feature importances: {}'.format(clf2.feature_importances_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 2: Breast Cancer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Breast cancer dataset for classification\n",
    "cancer = load_breast_cancer()\n",
    "(X_cancer, y_cancer) = load_breast_cancer(return_X_y = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training-testing split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_cancer, y_cancer, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important features from a decision tree using gini index¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(criterion='gini', max_depth = 4, min_samples_leaf = 8,\n",
    "                            random_state = 0).fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy of DT classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))\n",
    "print('Accuracy of DT classifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,6),dpi=80)\n",
    "plot_feature_importances(clf, cancer.feature_names)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(criterion='entropy', max_depth = 4, min_samples_leaf = 8,\n",
    "                            random_state = 0).fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy of DT classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))\n",
    "print('Accuracy of DT classifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,6),dpi=80)\n",
    "plot_feature_importances(clf, cancer.feature_names)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-cross validation\n",
    "\n",
    "#### Instructions: \n",
    "\n",
    "<p style='color:red'> \n",
    "Please make a summary of the model performance (averaging k folds' results) using result_metrics_dict. Currently it shows the content of the dictionary. \n",
    "</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "X = iris.data[:, 2:] # petal length and width\n",
    "y = iris.target\n",
    "\n",
    "from sklearn.model_selection import KFold # import k-fold validation\n",
    "\n",
    "kf = KFold(n_splits=3, random_state=None, shuffle=True) # Define the split - into 2 folds \n",
    "\n",
    "kf.get_n_splits(X) # returns the number of splitting iterations in the cross-validator\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(max_depth=2, random_state=42)\n",
    "\n",
    "# !!!!! Please make a summary of the model performance (averaging k folds' results) using result_metrics_dict \n",
    "for train_index, test_index in kf.split(X):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    tree_clf.fit(X_train, y_train)\n",
    "    y_pred = tree_clf.predict(X_test)\n",
    "    \n",
    "    # Print classification report\n",
    "    target_names = iris.target_names\n",
    "    result_metrics = classification_report(y_test, y_pred, target_names=target_names)\n",
    "    \n",
    "    print(result_metrics)\n",
    "    \n",
    "    # Once you get dictionary of metrics, access the values using dictionary\n",
    "    result_metrics_dict = classification_report(y_test, y_pred, target_names=target_names, output_dict=True)\n",
    "    \n",
    "    print(result_metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
